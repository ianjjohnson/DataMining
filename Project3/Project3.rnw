\documentclass[12pt]{article}
\usepackage[margin=0.9in]{geometry} 
\usepackage{enumitem}
\usepackage{graphicx, subfig}
\setlist{noitemsep}

\begin{document}

\begin{titlepage}
\vspace*{\fill}
\begin{center}
      {\Huge Association Rule and Frequent Itemset Analysis for Syngenta Soybean Data}\\[0.5cm]
      {\Large Comparing Test and Check Seed Results}\\[1.0cm]
      {\Large Ian Johnson}\\[0.4cm]
      {\Large Southern Methodist University}\\[0.4cm]
      \today
\end{center}
\vspace*{\fill}
\end{titlepage}

\begin{titlepage}
\vspace*{\fill}
\begin{center}
  
 \tableofcontents
     
\end{center}
\vspace*{\fill}
\end{titlepage}

\begin{titlepage}
\vspace*{\fill}
\begin{center}
  
      {\Large Executive Summary}\\[1.0cm]

     This report uses association rule and frequent itemset mining to explore the dataset from the Informs OR Student Competition related to Syngenta soybean seed selection and sales optimization. The dataset is split into two subsets - check seeds and test seeds - and the two subsets are converted to transaction sets after data discretization is performed. Association rules and frequent itemsets are mined from the two disjoint datasets, and the resulting rules and items are compared between sets using various metrics and visualizations. The two disjoint sets are found to be quite similar, and the conclusion is made that the two sets are statistically similar, and that it is viable, for the purpose of the OR competition, to use exclusively the check set to build a predictive model for the entire dataset for classification of seed graduation, or for regression of bags sold.\\[3.0cm]
     
\end{center}
\vspace*{\fill}
\end{titlepage}


\section{Data Preparation}

\subsection{Data Introduction}
This report will analyze transaction data generated from the Syngenta Informs OR Competition dataset \textsuperscript{[1]}. This data contains information about soybean seed tests which are used to decide which seed varieties will go to market and be sold by Syngenta. Potential seeds are tested in a 3-tiered testing system. First, all potential seeds are tested in 10 locations across the US. The top 15\% of those seeds continue to the second and third tiers, at which all seeds are tested in 30 locations across the US, and the top 15\% are selected and moved onto the next round. Seeds which make it through all 3 tiers of testing and outperform existing seeds become new seeds sold by Syngenta. Such seeds have sales data in the OR competition dataset.

The raw Informs OR dataset is table data where each row represents an individual test for a given seed. The columns are:
\begin{itemize}
\item Experiment Number (\textit{nominal}) - A unique identifier for experiment represented by a given row
\item Seed Variety (\textit{nominal}) - A unique identifier for the variety of a seed
\item Seed Family (\textit{nominal}) - A unique identifier for the family of a seed (there are many varieties in each family)
\item Location (\textit{nominal}) - A 4-digit code for the location where the test occurred
\item Check (\textit{nominal}) - A binary attribute which is set to 1 (\textit{true}) if the seed being tested is already at market and being used for comparison to potential new seeds
\item RM (Relative Maturity) (\textit{interval}) - A floating point number between 2 and 5 which represents the rate at which the variety of seed matures
\item Class Of (\textit{interval}) - The year that the seed "graduated" to market, or "." if the seed did not graduate
\item Grad (\textit{nominal}) - A binary attribute which is set to 1 (\textit{true}) if the seed being tested graduated after the given test
\item Bags Sold (\textit{ratio}) - The number of bags of seeds sold in the first year after this seed went to market or "." if the seed didn't go to market
\item Yield (\textit{ratio}) - The number of bushels of soybeans produced per acre by the seed during this test
\item Replication Number (\textit{nominal}) - An integer code used to delineate two experiments which use the same seed and same location and same year
\item Year (\textit{interval}) - The year when the experiment occurred
\end{itemize}

Before transaction data is generated from this raw dataset, it will be manipulated and formatted such that it becomes easiest to work with.

\subsection{Data Formatting and Encoding}

The first simple modification made to the dataset is that rows with matching experiment numbers and separate replication numbers are averaged (so that every single row in the data represents a unique year-variety-location combination). This simplifies further analysis, and also makes each row more representative of the seed variety in question. 

Subsequently, the dataset is ordered by variety, year, and location. This is a simple housekeeping decision to make forthcoming analyses easier.

\subsubsection{Location Clustering}
There are 152 unique locations used for testing in the dataset. In order to reduce the number of possible values of the location factor, clustering is used to reduce the location to a location cluster.

K-means clustering will be used, with the implementation from CRAN package "flexclust" \textsuperscript{[2]}.

An in-depth look at optimal clustering strategies may be warranted. However, because this report is focused on association rule mining, K-means will be used as a novel first-attempt at clustering.

Location clustering was performed by aggregating the dataset by location and computing the mean of yield, relative maturity, and bags sold of the seeds tested at that location. The resulting dataset was clustered (without the location variable included), and the resulting cluster for each location was assigned to that location.

\begin{center}
\includegraphics[]{clustering}

\textit{Figure 1.1 - A visualization of the K-means clustering algorithm output, with K=4}
\end{center}

Figure 1.1 shows the result of clustering the data using K-means clustering with K=4. The result is visualized in 2-dimensions using the 2 top components from principle component analysis which is performed on the aggregated location data. PCA is performed using CRAN package "caret" \textsuperscript{[3]}.

Note that in this 2D space, the locations appear to be dispersed in a single large cluster, so the resulting clusters are not particularly meaningful. This will be considered when the association rules are analyzed.

After locations are clustered, a new attribute is added to the data table called locationGroup, which is a nominal integer in the range 1-4 which represents which cluster the location resides in.

\subsubsection{A Divergence Between this Report and OR Competition Work}
For the OR Competition work, I one-hot encode the year column, separate the dataframe into a set of dataframes by year, and then use columnar-binding to combine the data frames into one master data frame where each row includes data for each seed for each year, instead of including duplicate rows for any given seed variety. This format is used to facilitate classification or regression for bags sold information. However, for this report, the dataset is left as one large table with duplicate rows for each seed variety (no two rows are truly "duplicates" but there are multiple rows per seed). This is done in the hopes that it will allow for more insight from the association rule part of the analysis.

The dataset which will be used moving forward has the following columns:
\begin{itemize}
\item Seed Variety (\textit{nominal}) - A unique identifier for the variety of a seed
\item Seed Family (\textit{nominal}) - A unique identifier for the family of a seed (there are many varieties in each family)
\item Location (\textit{nominal}) - A 4-digit code for the location where the test occurred
\item Check (\textit{nominal}) - A binary attribute which is set to 1 (\textit{true}) if the seed being tested is already at market and being used for comparison to potential new seeds
\item RM (Relative Maturity) (\textit{interval}) - A floating point number between 2 and 5 which represents the rate at which the variety of seed matures
\item Grad (\textit{nominal}) - A binary attribute which is set to 1 (\textit{true}) if the seed being tested graduated after the given test
\item Bags Sold (\textit{ratio}) - The number of bags of seeds sold in the first year after this seed went to market or "." if the seed didn't go to market
\item Yield (\textit{ratio}) - The number of bushels of soybeans produced per acre by the seed during this test
\item Year (\textit{interval}) - The year when the experiment occurred
\item Location Group (\textit{nominal}) - The cluster number for the location of this experiment
\end{itemize}

Note that a few columns have been removed, including experiment number and replication number. The experiment number has no real meaning, and the replication number has been aggregated away.

\subsection{Data Discretization}

\subsubsection{Yield Discretization}
Based on the Syngenta problem statement, that at each test year, only the top 15\% of seeds of move on to the subsequent year, it is meaningful to discretize yield results into 7 sections by equal frequency, such that approximately 15\% of the seeds fall into each section after discretization.

\begin{center}
<<echo=FALSE, fig=TRUE>>=
df <- read.csv('../../Competition/data/clusteredLocations.csv')
df$ratio <- df$yield / df$rm
hist(df$yield, main = "Histogram of Yield Prior to Discretization",freq = FALSE)
lines(density(df$yield))
@
\textit{Figure 1.2 - Histogram of yield prior to discretization}
\end{center}

Figure 1.2 shows that the yield of a soybean experiment follows a normal distribution, so equal-frequency discretization will yield much smaller ranges in the middle section of the data than on the outside sections. This is okay, however, as we're most interested in identifying which seeds are the highest and lowest performing without excluding too many seeds from the top tiers by using equal-width discretization.

\begin{center}
<<echo=FALSE>>=
library(arulesCBA)
df$yield <- discretize(df$yield, method="frequency", categories = 6)
table(df$yield)
@
\textit{Figure 1.3 - Number of rows in each discretized yield category}
\end{center}

Figure 1.3 shows that, after discretization, the yield attribute in the dataframe is split into 6 evenly-filled categories.

Discretization is performed using CRAN package "arules" \textsuperscript{[4]}

\subsubsection{Relative Maturity Discretization}
Relative maturity, as defined by the Syngenta problem statement, is a representation of the number of months that it takes for a soybean seed to mature, where lower values are preferred.

In order to inform the discretization strategy decision for relative maturity (RM), a histogram of the attribute is plotted in Figure 1.4.

\begin{center}
<<echo=FALSE, fig=TRUE>>=
hist(df$rm, main = "Histogram of RM Prior to Discretization",freq = FALSE)
lines(density(df$rm))
@
\textit{Figure 1.4 - Histogram of relative maturity prior to discretization}
\end{center}

Figure 1.4 shows that RM, much like yield, is normally distributed. While RM is slightly skewed, it stands to reason that the same discretization strategy can apply.

\begin{center}
<<echo=FALSE>>=
library(arulesCBA)
df$rm <- discretize(df$rm, method="frequency", categories = 6)
table(df$rm)
@
\textit{Figure 1.5 - Number of rows in each discretized RM category}
\end{center}

Figure 1.5 shows that, after discretization, the RM variable is split into 6 evenly-filled categories, much like yield.

\subsubsection{An Additional Feature}

An optimal seed will produce the maximal amount of soybeans in the minimum amount of time. Therefore, the yield-to-rm ratio may be a meaningful attribute when it comes to soybean seed evaluation.

The yield-to-rm ratio, which will be called 'yield ratio,' is computed using a row-wise quotient of yield over rm, and the distribution of the new attribute is shown in figure 1.6. Note that the row-wise quotient is computed before the yield and rm variables are discretized, so the result is a true division of the original attributes and is independent of previous discretization.

\begin{center}
<<echo=FALSE, fig=TRUE>>=
hist(df$ratio[df$ratio < 100], main = "Histogram of Ratio Prior to Discretization",freq = FALSE)
lines(density(df$ratio[df$ratio < 100]))
@

\textit{Figure 1.6 - Histogram of yield ratio prior to discretization}
\end{center}

Yield ratio, like yield and RM, is normally distributed, so it can be discretized using the same strategy used for yield and RM (6-way frequency-based discretization).

\begin{center}
<<echo=FALSE>>=
df$ratio <- discretize(df$ratio, method="frequency", categories = 6)
table(df$ratio)
@

\textit{Figure 1.7 - Number of rows in each discretized yield ratio category}
\end{center}

Figure 1.7 shows that, after discretization, the yield ratio variable is split up into 6 evenly-filled categories.

\subsection{Transaction Set Creation}
The dataset will be partitioned into two transaction sets based on the "check" variable. The resulting two itemsets, therefore, will represent test seeds and check seeds, respectively. One set will include exclusively seeds that are already at market, and the other set will contain seeds that are currently being tested.

\begin{center}
<<echo=FALSE>>=

df$X.1 <- NULL
df$X   <- NULL
df$year <- as.factor(df$year)
df$locationGroup <- as.factor(df$locationGroup)
df$repno <- NULL


check <- as(df[df$check == "True",][c(1:5,7:13)], 'transactions')
test  <- as(df[df$check != "True",][c(1:5,7:13)], 'transactions') 
@
\begin{tabular}{|l|c|}
\hline
Check & 42842 \\
\hline
Test & 215411 \\
\hline
\end{tabular}

\textit{Figure 1.8 - Number of rows in each of the two transaction sets}
\end{center}

Figure 1.8 shows the number of check and non-check rows in the original dataset, and therefore the number of rows in the two transaction sets being built. It is important to note that the non-check transaction set is much larger than the check transactions set.

\subsubsection{Transaction Set Summary}

\begin{center}
<<echo=FALSE>>=
summary(check)
@

\textit{Figure 1.9 - Summary information for the check transaction set}
\end{center}

Figure 1.9 shows a summary of the check transaction set, whose most frequent items are \textit{grad=.} and \textit{bagsold=.} (which represents all non-graduating seeds). This means that there will likely be a number of non-meaningful association rules built, as these items essentially represent missing data. However, this will be handled in rule post-processing by only selecting rules which are of interest.

The summary for the test transaction set is omitted in the interest of brevity.

\subsubsection{Item Frequency Plot}

Figure 1.10 shows an item frequency plot for individual items in the check transaction set. 

\begin{center}
<<echo=FALSE, fig=TRUE>>=
library(arulesViz)
itemFrequencyPlot(check, topN=20)
@

\textit{Figure 1.10 - Item frequency plot for check transaction set}
\end{center}

Figure 1.10 shows that, beyond the 3 high frequency missing data items, the most frequent items are years and location groups. This is reasonable, since location group and year were discretized into 3 and 5 categories, respectively, while the yield, rm, and ratio statistics were discretized into 6 categories, and all of those categories are nearly equally filled.

\section{Modeling}

\subsection{The Check Variety Itemset}
First, the check variety itemset will be evaluated. A number of frequent itemsets and association rules will be generated with the check variety itemset, and they will be analyzed to unearth trends or meaningful information from the data.

\subsubsection{Check Variety Frequent Itemsets}

To begin our analysis, frequent itemsets will be mined from the check dataset with the default support constraint of 0.05.
Figure 2.1 shows the first 10 most frequent itemsets (the first 10 items in the itemset after the set is sorted by support).

<<echo=FALSE, results=hide>>=
sets.check <- apriori(check, parameter=list(target="frequent", support=0.05))
@


\begin{center}
<<echo=FALSE>>=

sets.check <- sort(sets.check, by="support")

inspect(head(sets.check, n=10))
@
\textit{Figure 2.1 - Top 10 most frequent itemsets}
\end{center}

Figure 2.1 shows that the majority of the high-frequency itemsets include the "." characteristic, which represents missing data in the original dataset. Therefore, we will eliminate the rules that include that characteristic and show the new top-5.

\begin{center}
<<echo=FALSE>>=
inspect(sets.check[c(8,9,20,32,33)])
@
\textit{Figure 2.2 - Top 5 most frequent itemsets, excluding "." items}
\end{center}

Figure 2.2 shows that the most frequent itemsets are, in fact, single item itemsets which represent years and locations. This is expected, given the results shown in Figure 1.9.

\subsubsection{Closed Itemsets}
The list of mined itemsets from the previous section will be subsetted to isolate only closed itemsets. Closed itemsets are itemsets for which no immediate supersets have the same support as the itemset.

\begin{center}
<<echo=FALSE>>=
sets.check.closed <- sets.check[is.closed(sets.check)]
inspect(head(sort(sets.check.closed, by="support")[c(3,8,9,11,15)]))
@
\textit{Figure 2.3 - Top 5 most frequent closed itemsets, excluding "." items}
\end{center}

Figure 2.3 shows the top 5 most frequent closed itemsets. Once again, the itemsets have been post-processed to exclude itemsets which include "." items. This is the first figure of frequent itemsets which includes some non-trivial itemsets. It shows that $rm=[2.2,2.6)$ and $yield=[67.9,124.0]$ are both frequent itemsets. However, because these are single-item itemsets, and the items in question were discretized using equal frequency, these particular itemsets are not particularly meaningful. 

That being said, this may nonetheless meaningful, because it means that these particular relative maturity and yield ranges occur more frequently in the check dataset than in the test dataset, since the two datasets were discretized together. This relative maturity range is the second lowest range, so this may indicate that low relative maturity seeds are more likely to go to market, because the seeds at market being used at tests are most likely to have low relative maturity. 

The same can be said for the yield range. The most frequent yield range in the check data is the highest possible yield range. This indicates that high-yield seeds are more likely to go to market, as the seeds at market being used for testing have high yield. Therefore, at this point it can be, on a working basis, inferred that high-yield and low-rm seeds are optimal for going to market.


\subsubsection{Maximal Itemsets}
The original list of mined itemsets will be subsetted once more, but this time to isolate maximal itemsets. Maximal frequent itemsets are frequent itemsets for which none of the immediate supersets is frequent.

\begin{center}
<<echo=FALSE>>=
sets.check.maximal <- sets.check[is.maximal(sets.check)]
inspect(head(sort(sets.check.maximal, by="support")))
@
\textit{Figure 2.4 - Top 5 most frequent maximal itemsets}
\end{center}

Figure 2.4 shows the top-frequency maximal itemsets. Here, the "." items have been included, as all of the frequent maximal itemsets include some non-"." attributes alongside the "." attributes.
In this set of itemsets, we see less meaningful data than in the prior, as each itemset includes a locationGroup and year item, which are somewhat novel attributes that, in isolation, don't provide much insight to our analysis.

\subsection{Test Variety Frequent Itemsets}

To compare with the check variety itemset frequent itemsets, a set of frequent itemsets will be generated from the test transaction set.

<<echo=FALSE, results=hide>>=
sets.test <- apriori(test, parameter=list(target="frequent", support=0.05))
@


\begin{center}
<<echo=FALSE>>=
sets.test <- sort(sets.test, by="support")

inspect(sets.test[c(8,16,20,28,33)])
@
\textit{Figure 2.5 - Top 5 most frequent itemsets, excluding "." items, for the test data}
\end{center}

Figure 2.5 shows the top 5 itemsets by frequency from the test dataset, excluding missing (".") items. Much like for the test dataset, we can see that these itemsets are not particularly meaningful, as they are all single-item itemsets representing years and location groups.


\subsubsection{Closed Itemsets}
Next, closed itemsets will be subsetted from the entire set of frequent itemsets from the test dataset.

\begin{center}
<<echo=FALSE>>=
sets.test.closed <- sets.test[is.closed(sets.test)]
inspect(head(sort(sets.test.closed, by="support")[c(3,5,7,10,13)]))
@
\textit{Figure 2.6 - Top 5 most frequent closed itemsets, excluding "." items}
\end{center}

The most frequent closed itemsets, shown in Figure 2.6, are mostly trivial once again. However, there is one non-trivial itemset, which is the itemset ${rm=[2.9,3.2]}$. This one-item itemset shows that the most frequent relative maturity range for the test data is the 3rd highest of the ranges. Since there are only 6 ranges for the relative maturity, this isn't particularly profound, but it does perhaps indicate that higher-rm seeds are more abundant in the test dataset than they are in the check dataset.

\subsubsection{Maximal Itemsets}
Finally, the maximal itemsets are subsetted from the entire frequent itemset set from the test dataset.

\begin{center}
<<echo=FALSE>>=
sets.test.maximal <- sets.test[is.maximal(sets.test)]
inspect(head(sort(sets.test.maximal, by="support")))
@
\textit{Figure 2.7 - Top 5 most frequent maximal itemsets}
\end{center}

The high-support maximal itemsets shown in Figure 2.7 show no obvious patterns, but instead a slew of various locations, years, relative maturity ranges, and yield ranges. Interestingly, one ratio range appears, the lowest possible range, but this is a single item out of 6 items, and so it likely has no strong implications about the test data.



\subsection{Itemset Comparison}

As a first novel comparison of the two sets of itemsets, we can compare the distribution of itemset cardinalities between the two transaction sets. Figures 2.8 shows the distributions of size of itemset for the check and test sets.

<<hista, echo=FALSE, fig=TRUE, include=FALSE, width=5, height=5>>=
barplot(table(size(sets.check)), xlab="itemset size", ylab="count",main="Histogram of Itemset Size for Check Itemset")
@

<<histb, echo=FALSE, fig=TRUE, include=FALSE, width=5, height=5>>=
barplot(table(size(sets.test)), xlab="itemset size", ylab="count",main="Histogram of Itemset Size for Test Itemset")
@


\begin{center}
\includegraphics[width=7cm, height=7cm]{project3-hista}
\includegraphics[width=7cm, height=7cm]{project3-histb}

\textit{Figure 2.8 - Distribution of frequent itemset cardinality from check and test itemsets}
\end{center}

Figures 2.8 show nearly identical distributions, which, on a structural level, indicates that the two datasets are quite similar. However, these plots provide little inference to any meaningful difference between the two datasets.

As a second comparison, the number of closed and maximal itemsets from the two datasets will be compared in Figure 2.9.

<<histc, echo=FALSE, fig=TRUE, include=FALSE, width=5, height=5>>=
barplot(c(
  frequent=length(sets.test),
  closed=length(sets.test.closed),
  maximal=length(sets.test.maximal)
  ), ylab="count", xlab="itemsets", main="Frequent Itemset Types for Test Itemset")
@

<<histd, echo=FALSE, fig=TRUE, include=FALSE, width=5, height=5>>=
barplot(c(
  frequent=length(sets.check),
  closed=length(sets.check.closed),
  maximal=length(sets.check.maximal)
  ), ylab="count", xlab="itemsets", main="Frequent Itemset Types for Check Itemset")
@
\begin{center}
\includegraphics[width=7cm, height=7cm]{project3-histc}
\includegraphics[width=7cm, height=7cm]{project3-histd}

\textit{Figure 2.9 - Frequent itemset types for check and test itemsets}
\end{center}

Figure 2.9 shows that, once again, the two itemsets appear to be very similar. Therefore, from an itemset-based perspective, there, in general, doesn't appear to be a large difference between the two. Association rules will now be mined to search for more insight into the difference between the two itemsets.

\subsection{Test Variety Association Rules}

To begin, association rules will be mined from the test transaction set with default apriori parameters, and the rules will be sorted by descending lift. 

<<echo=FALSE, results=hide>>=
rules.test <- apriori(test)
@


\begin{center}
<<echo=FALSE>>=

rules.test <- sort(rules.test, by="lift")
inspect(head(rules.test))
@
\textit{Figure 2.11 - Top-lift rules for the check transaction set}
\end{center}

460 rules were mined from the test transaction set using default apriori parameters. Figure 2.10 shows the top rules from the mined ruleset, based on lift. None of these rules are particularly meaningful, since they are all predicting locationGroup. However, there are likely more meaty rules inside of the ruleset, which should become useful in visualizations comparing the check and test rulesets.

\subsection{Check Variety Association Rules}

The same apriori parameters are used to mine rules from the check transaction set.

<<echo=FALSE,results=hide>>=
rules.check <- apriori(check)
@


\begin{center}
<<echo=FALSE>>=
rules.check <- sort(rules.check, by="lift")
inspect(head(rules.check))
@
\textit{Figure 2.11 - Top-lift rules for the test transaction set}
\end{center}

315 rules were mined from the check transaction set with default apriori parameters. Figure 2.11 shows the top rules from that ruleset, based on lift. The first rule is the only interesting rule among them, which shows that, with a confidence of 0.8755, seeds posed to be in the class of 2011 had a graduated value of "YES." This likely indicates that 2011 was a highly non-competitive year for the soybean seed graduates.

\subsection{Comparison and Visualization}
In the following section, a number of visualizations will be used to attempt to discern a distinction between the two transaction sets through the use of the association rules mined from those sets.

\subsubsection{Support vs Confidence}
The first visual comparison of the two sets of association rules will be a support vs confidence plot for all of the rules in each test set, color-coded by lift. Note that some jitter is added to each of the plots to separate duplicate points on the plots.

<<supptest, echo=FALSE, fig=TRUE, include=FALSE>>=
plot(rules.test,control=list(jitter=10), main="Test Set")
@
<<suppcheck, echo=FALSE, fig=TRUE, include=FALSE>>=
plot(rules.check,control=list(jitter=10), main="Check Set")
@

\begin{center}
\includegraphics[width=7cm, height=7cm]{project3-suppcheck}
\includegraphics[width=7cm, height=7cm]{project3-supptest}

\textit{Figure 2.12 - Support vs Confidence plots for the two sets of association rules}
\end{center}

Figure 2.12 shows us a number of things. First, the upper-bound of lift is much higher for the check dataset than for the test dataset. This indicates that there are a few very strong rules in the check dataset that do not have a counterpart in the test dataset. 

Additionally, there appear to be many more high-support rules in the test set than in the check set. This observation, however, is likely due to the discrepancy in size of the two datasets, as the test set is much larger than the check set.

Both rulesets have a large number of high-confidence, low-support rules, which often include "." values as the RHS of the rule. Those rules are generally not particularly meaningful. However, there are also a number of high-confidence, high-support rules in each dataset. These rules have more profound meanings, as a number of them have ratio scores as a RHS, but they have low lift, so they're unlikely to be strong predictors for the data.

The test set also appears to have a number of low-confidence, low-support, high-lift rules (dark red points in the bottom-left of the right graph). Those rules are the same rules isolated in Figure 2.11, which shows that those rules are generally not particularly meaningful, as they, in essence, associate a year and relative maturity with a locationGroup, and the locations were clustered based on those attributes to yield those locationGroups.

\subsubsection{Grouped Matrix Plots}

Next, grouped matrix plots will be used to attempt to identify trends among each of the two rulesets. A matrix plot is built for both sets, and both are shown in Figure 2.13.

<<matcheck, echo=FALSE, fig=TRUE, include=FALSE, width=7, height=10>>=
plot(rules.check, method="grouped", main="Check Set")
@
<<mattest,  echo=FALSE, fig=TRUE, include=FALSE, width=7, height=10>>=
plot(rules.test, method="grouped", main="Test Set")
@

\begin{center}
\includegraphics[width=7cm, height=10cm]{project3-matcheck}
\includegraphics[width=7cm, height=10cm]{project3-mattest}

\textit{Figure 2.13 - Grouped matrix plots for the two rulesets (check on the left, test on the right)}
\end{center}

Figure 2.13 shows that there are no strong rule-based trends toward any ratio or yield interval for either the check set or the test set. The check set appears to have one high-lift rule to predict graduation, but the remainder of the rules shown in the grouped matrix have location groups and "." attributes as the right-hand side. The same is true for the test set, whose grouped matrix rules only predict "." attributes, location groups, and the year 2012.

Beyond the simple interpretation - that there don't appear to be any strong association-rule trends to predict yield or yield ratio - it can also be inferred from Figure 2.13 that the check and test transaction sets are, in fact, quite similar, as the rulesets mined from the two sets don't appear to differ from one another in any meaningful way.


\subsubsection{Ruleset Graph Plots}

Finally, a ruleset graph visualization is used to compare the top-20 rules by lift from the two datasets. The two ruleset graphs for the two datasets are shown in Figure 2.14.

<<graphcheck,  echo=FALSE, fig=TRUE, include=FALSE, width=8, height=8>>=
plot(head(rules.check, n=20), method="graph", control=list(type="items"),main="Check Set")
@

<<graphtest,  echo=FALSE, fig=TRUE, include=FALSE, width=8, height=8>>=
plot(head(rules.test, n=20), method="graph", control=list(type="items"), main="Test Set")
@

\begin{center}
\includegraphics[width=7.5cm, height=7.5cm]{project3-graphcheck}
\includegraphics[width=7.5cm, height=7.5cm]{project3-graphtest}

\textit{Figure 2.14 - Ruleset graphs for the two rulesets}
\end{center}

Both of the ruleset graphs in Figure 2.14 shows that the items that dominate the top-lift rules are generally year, group, and location items. Both graphs have very few relative maturity, yield, or yield-ratio items, which indicates that no strong trends related to those variables were identified using association rule mining.

The previous visualizations and comparisons showed that, generally speaking, the check and test datasets are quite similar. The business implications of this result will be evaluated in the upcoming sections.


\section{Evaluation}

\subsection{Findings}

The principle finding of this report is that there is no significant difference in the test and check datasets. The lack of noticeable differences between the frequent itemsets and association rule sets generated in the previous section shows that, in general, there is no strong distinction to be made between the two sets based on frequent itemset and association rule mining. However, this does not preclude there being a statistically significant difference between the sets in some way.

One novel finding was that it appeared that, to some degree, low-relative maturity and high-yield seeds appeared more frequently in the check dataset. This falls in line with the business motivation of the problem: to produce seeds which produce a lot of soybeans and can be grown in various climates (as low-rm seeds are the only viable seeds in climates with short growing seasons). The frequency of high-yield, low-rm seeds in the check set may indicate that that type of seed is preferred for "graduation," as they seem to be over-represented in the graduated seed base. This finding may help inform the seed-selection process; however, there is not significant data to support this finding, so it should not be relied upon too heavily.

\subsection{Insights into Syngenta Competition}

As was previously discussed, the finding that low-rm, high-yield seeds appear more frequently in the check itemset can help inform the seed selection. Using this information, we can build a model which favors high-yield, low-rm seeds. This can be done in multiple ways, one of which being yield ratio feature creation. However, this would encourage a model to simply repeat the process as it has been done before, which may, in fact, not be the optimal solution to the problem. 

The fact that the test and check sets are so similar may, in fact, help inform a new model. Because the two sets are so similar, according to this report's findings, it is likely feasible to build a model from exclusively check varieties that could be used for regression of seeds sold for incoming seeds. This would help reduce the problem space to only graduating seeds, which would help eliminate some of the noisy/missing data in the test dataset.

\subsection{Result Usability}

The results discussed above can, in good faith, be applied to the Informs OR Syngenta competition; however, because the results came from only association rule and frequent itemset analysis, they should not be treated as an end-result, but instead a baseline. It is possible that there do, in fact, exist meaningful differences between the two subsets of the Syngenta experimental dataset. 

Having said that, I have chosen to build a classification model for bags sold using only the check dataset, as I perceive the check dataset to be quite similar to to the test dataset.


\begin{thebibliography}{9} 

\bibitem{syngenta} "2017 Problem." - INFORMS O.R. and Analytics Student Team Competition. N.p., n.d. Web. 03 Nov. 2016.
\bibitem{flexclust} Friedrich Leisch. A Toolbox for K-Centroids Cluster Analysis. Computational Statistics and Data Analysis, 51 (2), 526-544, 2006.
\bibitem{caret}  Max Kuhn. Contributions from Jed Wing, Steve Weston, Andre Williams, Chris Keefer, Allan Engelhardt, Tony Cooper, Zachary Mayer, Brenton Kenkel, the R Core Team, Michael Benesty, Reynald Lescarbeau, Andrew Ziem, Luca Scrucca, Yuan Tang and Can Candan. (2016). caret: Classification and Regression Training. R package version 6.0-68. https://CRAN.R-project.org/package=caret
\bibitem{arules}  Michael Hahsler, Christian Buchta, Bettina Gruen and Kurt Hornik (2016). arules: Mining Association Rules and Frequent Itemsets. R package version 1.5-0. https://CRAN.R-project.org/package=arules
%4 so far

\end{thebibliography} 

\end{document}



%Notes: 
%@TODO: Switch all figures to include fig number and refs
%Mapping by state in USA: https://gist.github.com/cdesante/4252133 for mapping USA
%State-to-school map: http://ope.ed.gov/accreditation/GetDownLoadFile.aspx
%Data Source: https://www.kaggle.com/mylesoneill/world-university-rankings
%Use this reference: http://colleges.usnews.rankingsandreviews.com/best-colleges/smu-3613

              